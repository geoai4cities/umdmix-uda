# UMDMix: Urban Multi-Domain Mixing (UMDMix) Based Unsupervised Domain Adaptation for LiDAR Semantic Segmentation
### Abstract
3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised domain adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts occurring from variations due to physical environment, data sparsity, and sensor variations. To address these limitations, we propose *UMDMix*, a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. *UMDMix* integrates a teacher-student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns more significance to semantically rich neighborhoods. A combination of entropy regularizer and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that *UMDMix* achieves an average improvement of 13\% on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous state-of-the-art (SOTA) UDA methods.
